{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "\n",
    "# Thiết lập seed để kết quả có thể tái tạo\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# 1. Tải và khám phá dữ liệu\n",
    "# Giả sử bạn có dữ liệu gian lận, thay đổi đường dẫn thích hợp\n",
    "# Ví dụ: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "print(f\"Kích thước dữ liệu: {df.shape}\")\n",
    "print(\"\\nThông tin dữ liệu:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nKiểm tra giá trị thiếu:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nThống kê mô tả:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Kiểm tra mất cân bằng dữ liệu\n",
    "print(\"\\nPhân phối nhãn:\")\n",
    "print(df['Class'].value_counts())\n",
    "print(f\"Tỷ lệ gian lận: {df['Class'].mean()*100:.2f}%\")\n",
    "\n",
    "# 2. Tiền xử lý dữ liệu\n",
    "# Chia tập dữ liệu\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Chia tập dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "print(f\"\\nKích thước tập huấn luyện: {X_train.shape}\")\n",
    "print(f\"Kích thước tập kiểm tra: {X_test.shape}\")\n",
    "\n",
    "# 3. Tạo và huấn luyện mô hình TabNet\n",
    "# Khởi tạo mô hình TabNet với các tham số\n",
    "tabnet_params = {\n",
    "    \"n_d\": 64,  # Chiều của decision prediction layer\n",
    "    \"n_a\": 64,  # Chiều của attention embedding\n",
    "    \"n_steps\": 5,  # Số bước trong mạng\n",
    "    \"gamma\": 1.5,  # Tham số kiểm soát sự dùng lại feature\n",
    "    \"n_independent\": 2,  # Số bước độc lập\n",
    "    \"n_shared\": 2,  # Số bước chia sẻ\n",
    "    \"lambda_sparse\": 1e-3,  # Tham số điều chỉnh sparse regularization\n",
    "    \"optimizer_fn\": torch.optim.Adam,\n",
    "    \"optimizer_params\": dict(lr=2e-2),\n",
    "    \"mask_type\": \"entmax\",  # Loại mask để sử dụng\n",
    "    \"scheduler_params\": dict(\n",
    "        mode=\"min\", patience=5, min_lr=1e-5, factor=0.5,\n",
    "    ),\n",
    "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"verbose\": 1\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = TabNetClassifier(**tabnet_params)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_name=['train', 'test'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# 4. Đánh giá mô hình\n",
    "# Dự đoán\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Báo cáo phân loại\n",
    "print(\"\\nBáo cáo phân loại:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Ma trận nhầm lẫn\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Bình thường', 'Gian lận'], \n",
    "            yticklabels=['Bình thường', 'Gian lận'])\n",
    "plt.xlabel('Dự đoán')\n",
    "plt.ylabel('Thực tế')\n",
    "plt.title('Ma trận nhầm lẫn')\n",
    "plt.show()\n",
    "\n",
    "# Đường cong ROC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'TabNet (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Đường cong ROC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5. Phân tích đặc trưng quan trọng\n",
    "# TabNet có thể cung cấp thông tin về đặc trưng quan trọng\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Hiển thị top 15 đặc trưng quan trọng nhất\n",
    "plt.figure(figsize=(10, 8))\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False).head(15)\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Top 15 đặc trưng quan trọng nhất')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Giải thích mô hình cho từng dự đoán\n",
    "# TabNet cho phép giải thích từng dự đoán cụ thể\n",
    "explain_matrix, masks = model.explain(X_test)\n",
    "\n",
    "# Hiển thị sự giải thích cho một giao dịch gian lận cụ thể\n",
    "fraud_indices = np.where(y_test == 1)[0]\n",
    "if len(fraud_indices) > 0:\n",
    "    fraud_idx = fraud_indices[0]  # Lấy một giao dịch gian lận đầu tiên\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(len(feature_names)), X_test[fraud_idx])\n",
    "    plt.xticks(range(len(feature_names)), feature_names, rotation=90)\n",
    "    plt.title('Giá trị đặc trưng của giao dịch gian lận')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(len(feature_names)), explain_matrix[fraud_idx])\n",
    "    plt.xticks(range(len(feature_names)), feature_names, rotation=90)\n",
    "    plt.title('Mức độ ảnh hưởng của đặc trưng đối với dự đoán')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nMô hình TabNet đã được huấn luyện và đánh giá thành công cho bài toán phát hiện gian lận!\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Định nghĩa các hàm đánh giá mô hình\n",
    "def evaluate_model(model, X, y, threshold=0.5, dataset_name=\"Unknown\"):\n",
    "    \"\"\"Đánh giá mô hình và trả về các metric cơ bản\"\"\"\n",
    "    # Dự đoán xác suất\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Tính AUC và Average Precision\n",
    "    auc = roc_auc_score(y, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y, y_pred_proba)\n",
    "\n",
    "    # Chuyển xác suất thành nhãn dựa vào ngưỡng\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    # Tạo báo cáo phân loại\n",
    "    class_report = classification_report(y, y_pred, output_dict=True)\n",
    "\n",
    "    # Tạo ma trận nhầm lẫn\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "    print(f\"\\n--- Kết quả đánh giá trên tập {dataset_name} ---\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Precision (Fraud): {class_report['1']['precision']:.4f}\")\n",
    "    print(f\"Recall (Fraud): {class_report['1']['recall']:.4f}\")\n",
    "    print(f\"F1-score (Fraud): {class_report['1']['f1-score']:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'avg_precision': avg_precision,\n",
    "        'precision': class_report['1']['precision'],\n",
    "        'recall': class_report['1']['recall'],\n",
    "        'f1': class_report['1']['f1-score'],\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'conf_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, title=\"Ma trận nhầm lẫn\"):\n",
    "    \"\"\"Vẽ ma trận nhầm lẫn\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Bình thường', 'Gian lận'],\n",
    "                yticklabels=['Bình thường', 'Gian lận'])\n",
    "    plt.xlabel('Dự đoán')\n",
    "    plt.ylabel('Thực tế')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pr_curve(y_true, y_score, title=\"Precision-Recall Curve\"):\n",
    "    \"\"\"Vẽ đường cong Precision-Recall\"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, label=f'AP={average_precision_score(y_true, y_score):.3f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Định nghĩa hàm objective cho Optuna\n",
    "def objective(trial):\n",
    "    \"\"\"Hàm mục tiêu cho Optuna để tối ưu hóa siêu tham số\"\"\"\n",
    "    # Định nghĩa không gian tìm kiếm siêu tham số\n",
    "    tabnet_params = {\n",
    "        \"n_d\": trial.suggest_int(\"n_d\", 8, 64),\n",
    "        \"n_a\": trial.suggest_int(\"n_a\", 8, 64),\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0),\n",
    "        \"n_independent\": trial.suggest_int(\"n_independent\", 1, 5),\n",
    "        \"n_shared\": trial.suggest_int(\"n_shared\", 1, 5),\n",
    "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-2, log=True),\n",
    "        \"optimizer_fn\": torch.optim.Adam,\n",
    "        \"optimizer_params\": {\n",
    "            \"lr\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        },\n",
    "        \"mask_type\": trial.suggest_categorical(\"mask_type\", [\"sparsemax\", \"entmax\"]),\n",
    "        \"momentum\": trial.suggest_float(\"momentum\", 0.01, 0.4),\n",
    "        \"scheduler_params\": {\n",
    "            \"mode\": \"max\",\n",
    "            \"patience\": trial.suggest_int(\"scheduler_patience\", 3, 10),\n",
    "            \"min_lr\": 1e-5,\n",
    "            \"factor\": trial.suggest_float(\"scheduler_factor\", 0.1, 0.5),\n",
    "        },\n",
    "        \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        \"verbose\": 0,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "\n",
    "    # Tham số huấn luyện\n",
    "    max_epochs = trial.suggest_int(\"max_epochs\", 30, 100)\n",
    "    patience = trial.suggest_int(\"patience\", 5, 15)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [512, 1024, 2048, 4096])\n",
    "    virtual_batch_size = trial.suggest_categorical(\"virtual_batch_size\", [64, 128, 256, 512])\n",
    "\n",
    "    # Khởi tạo mô hình TabNet\n",
    "    model = TabNetClassifier(**tabnet_params)\n",
    "\n",
    "    # Try-except để xử lý các lỗi có thể xảy ra trong quá trình huấn luyện\n",
    "    try:\n",
    "        # Huấn luyện mô hình\n",
    "        model.fit(\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "            eval_name=['train', 'val'],\n",
    "            eval_metric=['auc'],\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        # Dự đoán trên tập validation\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "        val_ap = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "        # Lưu giá trị tốt nhất của AUC vào thử nghiệm\n",
    "        trial.set_user_attr(\"best_epoch\", model.best_epoch)\n",
    "        trial.set_user_attr(\"val_ap\", val_ap)\n",
    "\n",
    "        print(f\"Trial #{trial.number}: val_auc = {val_auc:.4f}, val_ap = {val_ap:.4f}, \"\n",
    "              f\"best_epoch = {model.best_epoch}, n_d = {tabnet_params['n_d']}, \"\n",
    "              f\"n_a = {tabnet_params['n_a']}, batch_size = {batch_size}\")\n",
    "\n",
    "        return val_auc\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi trong trial #{trial.number}: {e}\")\n",
    "        return float('-inf')  # Trả về giá trị thấp nếu có lỗi\n",
    "\n",
    "\n",
    "# Chạy tối ưu hóa siêu tham số\n",
    "# Thiết lập seed\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Tạo một nghiên cứu Optuna mới\n",
    "study_name = \"tabnet_fraud_detection\"\n",
    "storage_name = \"sqlite:///tabnet_fraud_detection.db\"  # Lưu kết quả vào SQLite DB\n",
    "\n",
    "# Kiểm tra xem đã có nghiên cứu cũ chưa\n",
    "try:\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        load_if_exists=True,\n",
    "        direction=\"maximize\"\n",
    "    )\n",
    "    print(f\"Đã tải nghiên cứu hiện có với {len(study.trials)} trials đã hoàn thành.\")\n",
    "except:\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        direction=\"maximize\"\n",
    "    )\n",
    "    print(\"Đã tạo nghiên cứu mới.\")\n",
    "\n",
    "# Số lượng thử nghiệm và thời gian tối đa\n",
    "n_trials = 30  # Điều chỉnh số lượng trials theo nhu cầu\n",
    "timeout = 3600 * 4  # Tối đa 4 giờ\n",
    "\n",
    "print(f\"Bắt đầu tối ưu hóa siêu tham số với {n_trials} trials...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Chạy tối ưu hóa\n",
    "study.optimize(objective, n_trials=n_trials, timeout=timeout)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"\\nĐã hoàn thành tối ưu hóa trong {duration / 60:.2f} phút.\")\n",
    "# Hiển thị kết quả tối ưu hóa\n",
    "# Lấy siêu tham số tốt nhất\n",
    "best_params = study.best_params\n",
    "best_trial = study.best_trial\n",
    "best_value = study.best_value\n",
    "\n",
    "print(\"\\n========= Kết quả tối ưu hóa siêu tham số =========\")\n",
    "print(f\"Best Trial: #{best_trial.number}\")\n",
    "print(f\"Best AUC: {best_value:.4f}\")\n",
    "print(f\"Best Average Precision: {best_trial.user_attrs['val_ap']:.4f}\")\n",
    "print(f\"Best Epoch: {best_trial.user_attrs['best_epoch']}\")\n",
    "\n",
    "print(\"\\nSiêu tham số tốt nhất:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"- {param}: {value}\")\n",
    "# Tạo mô hình cuối cùng với siêu tham số tốt nhất\n",
    "print(\"Huấn luyện mô hình cuối cùng với siêu tham số tốt nhất...\")\n",
    "\n",
    "# Khởi tạo tham số từ kết quả tối ưu hóa\n",
    "final_tabnet_params = {\n",
    "    \"n_d\": best_params[\"n_d\"],\n",
    "    \"n_a\": best_params[\"n_a\"],\n",
    "    \"n_steps\": best_params[\"n_steps\"],\n",
    "    \"gamma\": best_params[\"gamma\"],\n",
    "    \"n_independent\": best_params[\"n_independent\"],\n",
    "    \"n_shared\": best_params[\"n_shared\"],\n",
    "    \"lambda_sparse\": best_params[\"lambda_sparse\"],\n",
    "    \"optimizer_fn\": torch.optim.Adam,\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": best_params[\"learning_rate\"],\n",
    "    },\n",
    "    \"mask_type\": best_params[\"mask_type\"],\n",
    "    \"momentum\": best_params[\"momentum\"],\n",
    "    \"scheduler_params\": {\n",
    "        \"mode\": \"max\",\n",
    "        \"patience\": best_params[\"scheduler_patience\"],\n",
    "        \"min_lr\": 1e-5,\n",
    "        \"factor\": best_params[\"scheduler_factor\"],\n",
    "    },\n",
    "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    \"verbose\": 1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Huấn luyện mô hình cuối cùng trên tập huấn luyện + validation\n",
    "final_model = TabNetClassifier(**final_tabnet_params)\n",
    "final_model.fit(\n",
    "    X_train=X_train_val, y_train=y_train_val,\n",
    "    eval_set=[(X_train_val, y_train_val), (X_test, y_test)],\n",
    "    eval_name=['train_val', 'test'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=best_params[\"max_epochs\"],\n",
    "    patience=best_params[\"patience\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    virtual_batch_size=best_params[\"virtual_batch_size\"],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Đánh giá mô hình cuối cùng\n",
    "# Tìm ngưỡng tối ưu dựa trên tập validation\n",
    "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "\n",
    "# Tính F1 cho mỗi ngưỡng\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-10)\n",
    "optimal_threshold_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_threshold_idx]\n",
    "\n",
    "print(f\"Ngưỡng phân loại tối ưu: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Đánh giá trên tập test với ngưỡng tối ưu\n",
    "test_results = evaluate_model(final_model, X_test, y_test,\n",
    "                              threshold=optimal_threshold,\n",
    "                              dataset_name=\"Test\")\n",
    "\n",
    "# Vẽ ma trận nhầm lẫn\n",
    "plot_confusion_matrix(test_results['conf_matrix'], \"Ma trận nhầm lẫn - Tập Test\")\n",
    "\n",
    "# Vẽ đường cong Precision-Recall\n",
    "plot_pr_curve(y_test, test_results['y_pred_proba'], \"Precision-Recall Curve - Tập Test\")\n",
    "# fPhân tích đặc trưng quan trọng\n",
    "# Lấy tầm quan trọng của đặc trưng\n",
    "feature_importances = final_model.feature_importances_\n",
    "\n",
    "# Giả sử chúng ta có tên các đặc trưng\n",
    "try:\n",
    "    # Nếu X_train là DataFrame\n",
    "    if hasattr(X_train, 'columns'):\n",
    "        feature_names = X_train.columns.tolist()\n",
    "    else:\n",
    "        # Nếu không, tạo tên đặc trưng bằng số\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "except:\n",
    "    feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "\n",
    "# Tạo DataFrame để trực quan hóa\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Top 20 đặc trưng quan trọng nhất\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "plt.title('Top 20 đặc trưng quan trọng nhất')\n",
    "plt.tight_layout()\n",
    "plt.savefig('tabnet_feature_importance.png')\n",
    "plt.show()"
   ],
   "id": "a11096106d5e355f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
